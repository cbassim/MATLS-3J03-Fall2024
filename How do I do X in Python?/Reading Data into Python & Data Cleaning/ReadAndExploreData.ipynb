{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dressed-applicant",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reading data into python\n",
    "\n",
    "The data you will analyze in this course will generally be provided in CSV format. The easiest way to read and work with csv data in Python is via the [pandas Library](https://pandas.pydata.org/). Pandas provides conveinent data structures to manipulate and analyze data, built using the NumPy (a Python package to work with array elements). Consider taking a look at the [10 minute intro to pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacd9ede-383e-4a39-ab78-2a64000ae410",
   "metadata": {},
   "source": [
    "# Use the Python Pandas library for data manipulation and analysis.\n",
    "## Reading data into python with pandas\n",
    "\n",
    "We are following the convention to import Pandas in Python with the pd alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "radio-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-uncertainty",
   "metadata": {},
   "source": [
    "With Pandas you can use the read_csv(path_to_file) to automatically read and parse your csv. The only required arguement is the path to the csv file as a string or path object. The file can be hosted locally on your computer or online. Documentation for this method can be found [here](https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.read_csv.html).\n",
    "\n",
    "In this exmple we'll use the board thickness dataset\n",
    "\n",
    "There are many ways to read the dataset.  Use the .read_csv() to read in the dataset and store it as a Dataframe object in the variable that we choose to name it, here all_boards\n",
    "\n",
    "## Read from os\n",
    "The os commands can be used when the data is in the same folder as the python file - it defines the relative path between the files\n",
    "```python\n",
    "import os```\\\n",
    "```all_boards = pd.read_csv(os.getcwd() + os.sep + \"six-point-board-thickness.csv\")```\n",
    "\n",
    "## Read from open\n",
    "Import the dataset directly into your working directory and use it\n",
    "```all_boards = pd.read_csv('six-point-board-thickness.csv')```\n",
    "\n",
    "## Read from local computer\n",
    "```all_boards = pd.read_csv('C:/Users/person/Desktop/3J03/six-point-board-thickness')```\n",
    "\n",
    "## Read from online URL\n",
    "You can import from a URL with an import request, which will save he .csv to your working directory.   \n",
    "```import requests```\\\n",
    "```download_url = \"https://raw.githubusercontent.com/leebej/MATLS_3J03/main/ReadAndExploreData/six-point-board-thickness.csv?token=AWHGY67RONJF5BKT3HXZ6XDBPNB7K\"```\\\n",
    "```target_csv_path = \"six-point-board-thickness.csv\"```\\\n",
    "```response = requests.get(download_url)```\\\n",
    "```response.raise_for_status()    # Check that the request was successful```\\\n",
    "```with open(target_csv_path, \"wb\") as f:```\\\n",
    "    ```f.write(response.content)```\\    \n",
    "```print(\"Download ready.\")```\\\n",
    "```all_boards = pd.read_csv('six-point-board-thickness.csv')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e2c792a-cd87-429b-b03c-c5c97e113c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date.Time  Pos1  Pos2  Pos3  Pos4  Pos5  Pos6\n",
      "0      2010-02-18 3:04  1761  1739  1758  1677  1684  1692\n",
      "1      2010-02-18 3:37  1801  1688  1753  1741  1692  1675\n",
      "2      2010-02-18 3:37  1697  1682  1663  1671  1685  1651\n",
      "3      2010-02-18 3:37  1679  1712  1672  1703  1683  1674\n",
      "4      2010-02-18 3:37  1699  1688  1699  1678  1688  1705\n",
      "...                ...   ...   ...   ...   ...   ...   ...\n",
      "4995  2010-02-18 13:15  1690  1701  1690  1694  1735  1695\n",
      "4996  2010-02-18 13:15  1703  1674  1666  1694  1659  1728\n",
      "4997  2010-02-18 13:16  1657  1667  1675  1654  1648  1609\n",
      "4998  2010-02-18 13:16  1746  1717  1638  1723  1703  1706\n",
      "4999  2010-02-18 13:16  1668  1680  1668  1669  1651  1629\n",
      "\n",
      "[5000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "all_boards = pd.read_csv('six-point-board-thickness.csv')\n",
    "print(all_boards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1e5b0-9a2e-43b0-bef6-50e0ec786e6e",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "\n",
    "The dataframe provides conveinent built in ways to query the dataset, manipulate the data, and analyze the data.  Like the dataset, the dataframe in this case has 5000 rows and 7 columns.    \n",
    "The type() function is used to get the type of the object and check that it is a Pandas Dataframe.  \n",
    "The len() function will show the number of rows.  \n",
    "There are 3 attributes to describe the size of the dataframe:  \n",
    "> The .shape attribute will show the dimensionality.  The result is a tuple containing the number of rows and columns.  \n",
    "The .ndim atribute will show the number of dimensions of the dataframe.  \n",
    "The .size attribute will show the total number of values.  \n",
    "\n",
    "There are 3 components of the dataframe: This is what makes the arrangement of a data matrix tidy. First you should arrange, or tidy, your data into the form that you want.  \n",
    "> The columns names can be found with the .columns attribute.    \n",
    "The .index attribute returns the row labels  \n",
    "The .values attribute returns the dataframe values.  You can also use the .to_numpy() to create a 2D values array. \n",
    "\n",
    "Take a look at the first 5 rows of the dataframe with .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "numerical-trade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date.Time', 'Pos1', 'Pos2', 'Pos3', 'Pos4', 'Pos5', 'Pos6'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_boards.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d324df-b26e-4df4-9d3b-4fb68e26f13d",
   "metadata": {},
   "source": [
    "# Get to know the dataframe. \n",
    "You have imported a CSV file and had a first look at the data.  Now let's learn to examine the data systematically.  \n",
    "First, take a look at the different data types that the dataframe contains.  The columns of the dataframe contain specific data types.  Remember that a coulmn of a dataframe is a series object.  You can display all coumns with the data types with .info()  \n",
    "Or use the attribute .dtypes to return a series object with column names as labels ad corresponding data types as values.  \n",
    "Pandas uses the NumPy library to work with these data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "739369d1-38e5-46d7-a1d0-01067a181fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Date.Time  5000 non-null   object\n",
      " 1   Pos1       5000 non-null   int64 \n",
      " 2   Pos2       5000 non-null   int64 \n",
      " 3   Pos3       5000 non-null   int64 \n",
      " 4   Pos4       5000 non-null   int64 \n",
      " 5   Pos5       5000 non-null   int64 \n",
      " 6   Pos6       5000 non-null   int64 \n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 273.6+ KB\n"
     ]
    }
   ],
   "source": [
    "all_boards.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-sociology",
   "metadata": {},
   "source": [
    "## Accessing elements and manipulating data\n",
    "\n",
    "In this case, we're only interested in the board positions. The time the measurements were taken don't matter to us so we can drop that column (Date.Time) from the dataframe using the [.drop() method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html). Note that all of these data manipulation operators return another dataframe object so the same methods are applicable to the transformed data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adopted-cowboy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pos1  Pos2  Pos3  Pos4  Pos5  Pos6\n",
      "0     1761  1739  1758  1677  1684  1692\n",
      "1     1801  1688  1753  1741  1692  1675\n",
      "2     1697  1682  1663  1671  1685  1651\n",
      "3     1679  1712  1672  1703  1683  1674\n",
      "4     1699  1688  1699  1678  1688  1705\n",
      "...    ...   ...   ...   ...   ...   ...\n",
      "4995  1690  1701  1690  1694  1735  1695\n",
      "4996  1703  1674  1666  1694  1659  1728\n",
      "4997  1657  1667  1675  1654  1648  1609\n",
      "4998  1746  1717  1638  1723  1703  1706\n",
      "4999  1668  1680  1668  1669  1651  1629\n",
      "\n",
      "[5000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "boards_no_time = all_boards.drop(columns=[\"Date.Time\"])\n",
    "print(boards_no_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-absorption",
   "metadata": {},
   "source": [
    "Columns can be access by using their name in square brackers \\[\\] while rows can be access using their row (index) number and the [.iloc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html) property. iloc works similar to indexing on a list, the same type of slicing can be used \\[start:end\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "valuable-february",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1761\n",
      "1       1801\n",
      "2       1697\n",
      "3       1679\n",
      "4       1699\n",
      "        ... \n",
      "4995    1690\n",
      "4996    1703\n",
      "4997    1657\n",
      "4998    1746\n",
      "4999    1668\n",
      "Name: Pos1, Length: 5000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pos1 = boards_no_time['Pos1']\n",
    "print(pos1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "single-response",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pos1  Pos2  Pos3  Pos4  Pos5  Pos6\n",
      "0  1761  1739  1758  1677  1684  1692\n",
      "1  1801  1688  1753  1741  1692  1675\n",
      "2  1697  1682  1663  1671  1685  1651\n"
     ]
    }
   ],
   "source": [
    "# Get the first three rows of the dataframe\n",
    "first_three_rows = boards_no_time.iloc[0:3]\n",
    "print(first_three_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-right",
   "metadata": {},
   "source": [
    "You can use the .head() or .tail() methods to get a certain amount of elements from the top (head) or bottom (tail) of the dataframe. Syntactically they're the same, so I'll only show an example of one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "confused-glasgow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pos1  Pos2  Pos3  Pos4  Pos5  Pos6\n",
      "0  1761  1739  1758  1677  1684  1692\n",
      "1  1801  1688  1753  1741  1692  1675\n",
      "2  1697  1682  1663  1671  1685  1651\n"
     ]
    }
   ],
   "source": [
    "# Get the first three rows of pos 1 using head\n",
    "first_three_rows = boards_no_time.head(3)\n",
    "print(first_three_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-booking",
   "metadata": {},
   "source": [
    "Row and column access can also be combined together. The head and tail methods would work here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "threaded-internet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1761\n",
      "1    1801\n",
      "2    1697\n",
      "Name: Pos1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "first_column_three_rows = boards_no_time['Pos1'].iloc[0:3]\n",
    "print(first_column_three_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-medication",
   "metadata": {},
   "source": [
    "It is also possible to filter the dataframe based on the value in certain columns. Filtering the values returns a new dataframe with just the values that meet the condition (using the [.loc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html) property). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "foster-vertex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pos1  Pos2  Pos3  Pos4  Pos5  Pos6\n",
      "10    1546  1697  1654  1688  1668  1703\n",
      "11    1524  1668  1594  1686  1741  1730\n",
      "23    1608  1664  1641  1651  1633  1594\n",
      "48    1636  1650  1649  1666  1673  1665\n",
      "55    1643  1649  1624  1667  1662  1660\n",
      "...    ...   ...   ...   ...   ...   ...\n",
      "4932  1632  1608  1634  1667  1674  1706\n",
      "4933  1619  1692  1696  1711  1742  1728\n",
      "4961  1622  1627  1641  1664  1663  1660\n",
      "4969  1645  1680  1658  1747  1793  1808\n",
      "4974  1648  1612  1620  1637  1611  1694\n",
      "\n",
      "[539 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get all columns (the whole dataframe) rows which have pos1 < 1650\n",
    "less_1650 = boards_no_time.loc[boards_no_time['Pos1'] < 1650]\n",
    "\n",
    "print(less_1650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "composite-chaos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pos1\n",
      "10    1546\n",
      "11    1524\n",
      "23    1608\n",
      "48    1636\n",
      "55    1643\n",
      "...    ...\n",
      "4932  1632\n",
      "4933  1619\n",
      "4961  1622\n",
      "4969  1645\n",
      "4974  1648\n",
      "\n",
      "[539 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get only pos1 values for rows with pos1 < 1650\n",
    "pos1_less_1650 = boards_no_time.loc[boards_no_time['Pos1'] < 1650, ['Pos1']]\n",
    "print(pos1_less_1650)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-newspaper",
   "metadata": {},
   "source": [
    "Separate conditionals can be combined using boolean logic. In this case each conditional needs to be written in round brackets and the symbols change slightly. The element-wise logical symbols for use in these statements are:\n",
    "* and: &\n",
    "* or: |\n",
    "* not: ~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "disturbed-collins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pos1  Pos2  Pos3  Pos4  Pos5  Pos6\n",
      "23    1608  1664  1641  1651  1633  1594\n",
      "48    1636  1650  1649  1666  1673  1665\n",
      "55    1643  1649  1624  1667  1662  1660\n",
      "84    1618  1603  1607  1652  1666  1657\n",
      "86    1645  1685  1694  1705  1644  1542\n",
      "...    ...   ...   ...   ...   ...   ...\n",
      "4932  1632  1608  1634  1667  1674  1706\n",
      "4933  1619  1692  1696  1711  1742  1728\n",
      "4961  1622  1627  1641  1664  1663  1660\n",
      "4969  1645  1680  1658  1747  1793  1808\n",
      "4974  1648  1612  1620  1637  1611  1694\n",
      "\n",
      "[465 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get all columns that have 1600 < pos1 < 1650\n",
    "between_1600_1650 = boards_no_time.loc[(boards_no_time['Pos1'] > 1600) & (boards_no_time['Pos1'] < 1650)]\n",
    "print(between_1600_1650)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-present",
   "metadata": {},
   "source": [
    "Alternately, the .query() method can be used to succinctly query the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6daf7d8e-5319-4905-9b91-c3b99bb0f0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pos1  Pos2  Pos3  Pos4  Pos5  Pos6\n",
      "23    1608  1664  1641  1651  1633  1594\n",
      "48    1636  1650  1649  1666  1673  1665\n",
      "55    1643  1649  1624  1667  1662  1660\n",
      "84    1618  1603  1607  1652  1666  1657\n",
      "86    1645  1685  1694  1705  1644  1542\n",
      "...    ...   ...   ...   ...   ...   ...\n",
      "4932  1632  1608  1634  1667  1674  1706\n",
      "4933  1619  1692  1696  1711  1742  1728\n",
      "4961  1622  1627  1641  1664  1663  1660\n",
      "4969  1645  1680  1658  1747  1793  1808\n",
      "4974  1648  1612  1620  1637  1611  1694\n",
      "\n",
      "[465 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get all columns that have 1600 <pos1 < 1650\n",
    "between_1600_1650 = boards_no_time.query(\"1600 < Pos1 <1650\")\n",
    "print(between_1600_1650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a6956f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pos1\n",
      "23    1608\n",
      "48    1636\n",
      "55    1643\n",
      "84    1618\n",
      "86    1645\n",
      "...    ...\n",
      "4932  1632\n",
      "4933  1619\n",
      "4961  1622\n",
      "4969  1645\n",
      "4974  1648\n",
      "\n",
      "[465 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Just Pos1 column between 1600 and 1650 using .loc\n",
    "between_1600_1650 = boards_no_time.loc[(boards_no_time['Pos1'] < 1650) & (boards_no_time['Pos1'] > 1600), ['Pos1']]\n",
    "print(between_1600_1650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "57c676b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Series name: Pos1\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "5000 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 39.2 KB\n"
     ]
    }
   ],
   "source": [
    "#need to be in a dataframe to use query function\n",
    "pos1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b3c1ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Pos1    5000 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 39.2 KB\n",
      "      Pos1\n",
      "0     1761\n",
      "1     1801\n",
      "2     1697\n",
      "3     1679\n",
      "4     1699\n",
      "...    ...\n",
      "4995  1690\n",
      "4996  1703\n",
      "4997  1657\n",
      "4998  1746\n",
      "4999  1668\n",
      "\n",
      "[5000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Make a dataframe (not a series), see the additional []\n",
    "pos1data = boards_no_time[['Pos1']]\n",
    "pos1data.info()\n",
    "print(pos1data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17ed2a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Pos1\n",
      "23    1608\n",
      "48    1636\n",
      "55    1643\n",
      "84    1618\n",
      "86    1645\n",
      "...    ...\n",
      "4932  1632\n",
      "4933  1619\n",
      "4961  1622\n",
      "4969  1645\n",
      "4974  1648\n",
      "\n",
      "[465 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Just Pos1 column between 1600 and 1650 using .query\n",
    "bn1600_1650 = pos1data.query(\"1600 < Pos1 <1650\")\n",
    "print(bn1600_1650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15251fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
