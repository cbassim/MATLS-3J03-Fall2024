{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8cf8ca2-231c-425b-9453-55bad6e48e4b",
   "metadata": {},
   "source": [
    "# __Tutorial 1__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-applicant",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reading data into python\n",
    "\n",
    "The data you will analyze in this course will generally be provided in CSV format. The easiest way to read and work with csv data in Python is via the [pandas Library](https://pandas.pydata.org/). Pandas provides convenient data structures to manipulate and analyze data, built using the NumPy (a Python package to work with array elements). Consider taking a look at the [10 minute intro to pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacd9ede-383e-4a39-ab78-2a64000ae410",
   "metadata": {},
   "source": [
    "# Use the Python Pandas library for data manipulation and analysis.\n",
    "## Reading data into python with pandas\n",
    "\n",
    "We are following the convention to import Pandas in Python with the pd alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radio-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-uncertainty",
   "metadata": {},
   "source": [
    "With Pandas you can use the read_csv(path_to_file) to automatically read and parse your csv. The only required arguement is the path to the csv file as a string or path object. The file can be hosted locally on your computer or online. Documentation for this method can be found [here](https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.read_csv.html).\n",
    "\n",
    "In this example we'll use the board thickness dataset\n",
    "\n",
    "There are many ways to read the dataset.  Use the .read_csv() to read in the dataset and store it as a Dataframe object in the variable that we choose to name it, here all_boards\n",
    "\n",
    "## Read from os\n",
    "The os commands can be used when the data is in the same folder as the python file - it defines the relative path between the files\n",
    "```python\n",
    "import os```\\\n",
    "```all_boards = pd.read_csv(os.getcwd() + os.sep + \"six-point-board-thickness.csv\")```\n",
    "\n",
    "## Read from open\n",
    "Import the dataset directly into your working directory and use it\n",
    "```all_boards = pd.read_csv('six-point-board-thickness.csv')```\n",
    "\n",
    "## Read from local computer\n",
    "```all_boards = pd.read_csv('C:/Users/person/Desktop/4C03/six-point-board-thickness')```\n",
    "\n",
    "## Read from online URL\n",
    "You can import from a URL with an import request, which will save he .csv to your working directory.   \n",
    "```import requests```\\\n",
    "```download_url = \"https://raw.githubusercontent.com/leebej/IBEHS4C03/main/ReadAndExploreData/six-point-board-thickness.csv?token=AWHGY67RONJF5BKT3HXZ6XDBPNB7K\"```\\\n",
    "```target_csv_path = \"six-point-board-thickness.csv\"```\\\n",
    "```response = requests.get(download_url)```\\\n",
    "```response.raise_for_status()    # Check that the request was successful```\\\n",
    "```with open(target_csv_path, \"wb\") as f:```\\\n",
    "    ```f.write(response.content)```\\    \n",
    "```print(\"Download ready.\")```\\\n",
    "```all_boards = pd.read_csv('six-point-board-thickness.csv')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e2c792a-cd87-429b-b03c-c5c97e113c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date.Time  Pos1  Pos2  Pos3  Pos4  Pos5  Pos6\n",
      "0      2010-02-18 3:04  1761  1739  1758  1677  1684  1692\n",
      "1      2010-02-18 3:37  1801  1688  1753  1741  1692  1675\n",
      "2      2010-02-18 3:37  1697  1682  1663  1671  1685  1651\n",
      "3      2010-02-18 3:37  1679  1712  1672  1703  1683  1674\n",
      "4      2010-02-18 3:37  1699  1688  1699  1678  1688  1705\n",
      "...                ...   ...   ...   ...   ...   ...   ...\n",
      "4995  2010-02-18 13:15  1690  1701  1690  1694  1735  1695\n",
      "4996  2010-02-18 13:15  1703  1674  1666  1694  1659  1728\n",
      "4997  2010-02-18 13:16  1657  1667  1675  1654  1648  1609\n",
      "4998  2010-02-18 13:16  1746  1717  1638  1723  1703  1706\n",
      "4999  2010-02-18 13:16  1668  1680  1668  1669  1651  1629\n",
      "\n",
      "[5000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "all_boards=pd.read_csv('six-point-board-thickness.csv')\n",
    "print(all_boards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1e5b0-9a2e-43b0-bef6-50e0ec786e6e",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "\n",
    "The dataframe provides convenient built in ways to query the dataset, manipulate the data, and analyze the data.  Like the dataset, the dataframe in this case has 5000 rows and 7 columns.    \n",
    "The type() function is used to get the type of the object and check that it is a Pandas Dataframe.  \n",
    "The len() function will show the number of rows.  \n",
    "There are 3 attributes to describe the size of the dataframe:  \n",
    "> The .shape attribute will show the dimensionality.  The result is a tuple containing the number of rows and columns.  \n",
    "The .ndim atribute will show the number of dimensions of the dataframe.  \n",
    "The .size attribute will show the total number of values.  \n",
    "\n",
    "There are 3 components of the dataframe: This is what makes the arrangement of a data matrix tidy. First you should arrange, or tidy, your data into the form that you want.  \n",
    "> The columns names can be found with the .columns attribute.    \n",
    "The .index attribute returns the row labels  \n",
    "The .values attribute returns the dataframe values.  You can also use the .to_numpy() to create a 2D values array. \n",
    "\n",
    "Take a look at the first 5 rows of the dataframe with .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "numerical-trade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date.Time</th>\n",
       "      <th>Pos1</th>\n",
       "      <th>Pos2</th>\n",
       "      <th>Pos3</th>\n",
       "      <th>Pos4</th>\n",
       "      <th>Pos5</th>\n",
       "      <th>Pos6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-18 3:04</td>\n",
       "      <td>1761</td>\n",
       "      <td>1739</td>\n",
       "      <td>1758</td>\n",
       "      <td>1677</td>\n",
       "      <td>1684</td>\n",
       "      <td>1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-18 3:37</td>\n",
       "      <td>1801</td>\n",
       "      <td>1688</td>\n",
       "      <td>1753</td>\n",
       "      <td>1741</td>\n",
       "      <td>1692</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-18 3:37</td>\n",
       "      <td>1697</td>\n",
       "      <td>1682</td>\n",
       "      <td>1663</td>\n",
       "      <td>1671</td>\n",
       "      <td>1685</td>\n",
       "      <td>1651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-18 3:37</td>\n",
       "      <td>1679</td>\n",
       "      <td>1712</td>\n",
       "      <td>1672</td>\n",
       "      <td>1703</td>\n",
       "      <td>1683</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-18 3:37</td>\n",
       "      <td>1699</td>\n",
       "      <td>1688</td>\n",
       "      <td>1699</td>\n",
       "      <td>1678</td>\n",
       "      <td>1688</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date.Time  Pos1  Pos2  Pos3  Pos4  Pos5  Pos6\n",
       "0  2010-02-18 3:04  1761  1739  1758  1677  1684  1692\n",
       "1  2010-02-18 3:37  1801  1688  1753  1741  1692  1675\n",
       "2  2010-02-18 3:37  1697  1682  1663  1671  1685  1651\n",
       "3  2010-02-18 3:37  1679  1712  1672  1703  1683  1674\n",
       "4  2010-02-18 3:37  1699  1688  1699  1678  1688  1705"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(all_boards))\n",
    "len(all_boards)\n",
    "\n",
    "all_boards.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d324df-b26e-4df4-9d3b-4fb68e26f13d",
   "metadata": {},
   "source": [
    "# Get to know the dataframe. \n",
    "You have imported a CSV file and had a first look at the data.  Now let's learn to examine the data systematically.  \n",
    "First, take a look at the different data types that the dataframe contains.  The columns of the dataframe contain specific data types.  Remember that a coulmn of a dataframe is a series object.  You can display all coumns with the data types with .info()  \n",
    "Or use the attribute .dtypes to return a series object with column names as labels ad corresponding data types as values.  \n",
    "Pandas uses the NumPy library to work with these data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739369d1-38e5-46d7-a1d0-01067a181fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "celtic-sociology",
   "metadata": {},
   "source": [
    "## Accessing elements and manipulating data\n",
    "\n",
    "In this case, we're only interested in the board positions. The time the measurements were taken don't matter to us so we can drop that column (Date.Time) from the dataframe using the [.drop() method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html). Note that all of these data manipulation operators return another dataframe object so the same methods are applicable to the transformed data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-cowboy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "special-absorption",
   "metadata": {},
   "source": [
    "Columns can be access by using their name in square brackers \\[\\] while rows can be access using their row (index) number and the [.iloc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html) property. iloc works similar to indexing on a list, the same type of slicing can be used \\[start:end\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-february",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-response",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resistant-right",
   "metadata": {},
   "source": [
    "You can use the .head() or .tail() methods to get a certain amount of elements from the top (head) or bottom (tail) of the dataframe. Syntactically they're the same, so I'll only show an example of one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-glasgow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "solved-booking",
   "metadata": {},
   "source": [
    "Row and column access can also be combined together. The head and tail methods would work here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-internet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "working-medication",
   "metadata": {},
   "source": [
    "It is also possible to filter the dataframe based on the value in certain columns. Filtering the values returns a new dataframe with just the values that meet the condition (using the [.loc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html) property). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-vertex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-chaos",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-newspaper",
   "metadata": {},
   "source": [
    "Separate conditionals can be combined using boolean logic. In this case each conditional needs to be written in round brackets and the symbols change slightly. The element-wise logical symbols for use in these statements are:\n",
    "* and: &\n",
    "* or: |\n",
    "* not: ~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-collins",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "formed-present",
   "metadata": {},
   "source": [
    "Alternately, the .query() method can be used to succinctly query the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf7d8e-5319-4905-9b91-c3b99bb0f0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
